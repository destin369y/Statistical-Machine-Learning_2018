{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing OVA logistic regression for the CIFAR-10 dataset\n",
    "In this assignment, you will implement a one-vs-all logistic regression classifier, and apply it to a version of the CIFAR-10 object recognition dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CIFAR-10 dataset\n",
    "Open up a terminal window and navigate to the **datasets** folder inside the  **hw3** folder. Run the\n",
    "**get\\_datasets.sh**  script. On my Mac, I just type in **./get\\_datasets.sh** at the shell prompt.\n",
    "A new folder called **cifar\\_10\\_batches\\_py** will be created and it will contain $50000$ labeled\n",
    "images for training and $10000$ labeled images for testing. The function further partitions the $50000$ training \n",
    "images into a train set and a validation set for selection of hyperparameters. We have provided a function to\n",
    "read this data in **utils.py**. Each image is a $32 \\times 32$ array of RGB triples. It is preprocessed by\n",
    "subtracting the mean image from all images. We flatten each image into a 1-dimensional array of size\n",
    "3072 (i.e., $32\\times 32 \\times 3$). Then a 1 is appended to the front of that vector to handle \n",
    "the intercept term.  So the training set is a numpy matrix of size $49000\\times 3073$, \n",
    "the validation set is a matrix of size $1000\\times 3073$ and the set-aside test set \n",
    "is of size $10000\\times 3073$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the CIFAR-10 data broken up into train, validation and test sets\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = utils.get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a one_vs_all classifier for CIFAR-10\n",
    "In this part of the exercise, you will implement one-vs-all classifier by training multiple regularized binary logistic regression classifiers, one for each of the ten classes in our dataset. You should now complete the code in **one\\_vs\\_all.py** to train one classifier for each class. In particular, your code should return all the classifier parameters in a matrix $\\Theta \\in \\Re^{(d+1) \\times K}$,  where each column of $\\Theta$ corresponds to the learned logistic regression parameters for a class. You can do this with a for-loop from $0$ to $K − 1$, training each classifier independently.\n",
    "When training the classifier for class $k \\in \\{0, . . . , K − 1\\}$, you should build a new label for each example $x$ as follows: label $x$ as 1 if $x$ belomgs to class $k$ and zero otherwise. You can use sklearn's logistic regression function to learn each classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from one_vs_all import one_vs_allLogisticRegressor\n",
    "\n",
    "ova_logreg = one_vs_allLogisticRegressor(np.arange(10))\n",
    "\n",
    "# train \n",
    "reg = 1.0\n",
    "ova_logreg.train(X_train,y_train,reg)\n",
    "\n",
    "# predict on test set\n",
    "y_test_pred = ova_logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print 'one_vs_all on raw pixels final test set accuracy: %f' % (test_accuracy, )\n",
    "print confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the learned one-vs-all classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the learned weights for each class\n",
    "\n",
    "theta = ova_logreg.theta[1:,:].T # strip out the bias term\n",
    "theta = theta.reshape(10, 32, 32, 3)\n",
    "\n",
    "theta_min, theta_max = np.min(theta), np.max(theta)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in xrange(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  \n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  thetaimg = 255.0 * (theta[i].squeeze() - theta_min) / (theta_max - theta_min)\n",
    "  plt.imshow(thetaimg.astype('uint8'))\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing your functions with sklearn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "# train on train set with reg\n",
    "sklearn_ova = OneVsRestClassifier(linear_model.LogisticRegression(C=1.0/reg,penalty='l2',\n",
    "                                                                  fit_intercept=False,solver='lbfgs'))\n",
    "sklearn_ova.fit(X_train, y_train)     \n",
    "\n",
    "# predict on test set\n",
    "y_test_pred_sk = sklearn_ova.predict(X_test)\n",
    "\n",
    "sk_test_accuracy = np.mean(y_test == y_test_pred_sk)\n",
    "print 'one_vs_all on raw pixels final test set accuracy (sklearn): %f' % (sk_test_accuracy, )\n",
    "print confusion_matrix(y_test,y_test_pred_sk)                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the sklearn OVA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the learned weights for each class\n",
    "\n",
    "theta = sklearn_ova.coef_[:,1:].T # strip out the bias term\n",
    "theta = theta.reshape(10, 32, 32, 3)\n",
    "\n",
    "theta_min, theta_max = np.min(theta), np.max(theta)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in xrange(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  \n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  thetaimg = 255.0 * (theta[i].squeeze() - theta_min) / (theta_max - theta_min)\n",
    "  plt.imshow(thetaimg.astype('uint8'))\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
